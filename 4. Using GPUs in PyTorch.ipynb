{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch on GPU - Training Neural Networks with CUDA\n",
    "\n",
    "- Why Use GPUs?\n",
    "    - GPUs will allow us to compute parallel numerical computations\n",
    "        - This will make our code run much faster\n",
    "- Unfortunately, I am not able to execute GPU computations on my Macbook Pro :/\n",
    "- We can use **to()** function to move data to cpu or gpu\n",
    "    - to('cuda')\n",
    "    - to('cpu')\n",
    "- PyTorch is able to use multiple GPU's via an indexing system\n",
    "- Aside from data, it is also possible to move networks between devices\n",
    "    - This is done in the same way as moving data\n",
    "- What does it mean to move a network to a different device?\n",
    "    - It is not the network itself that is on device, it is rather the parameters that define the network which live on the device (remember this)\n",
    "    - The network is nothing but its parameters (hyper and not)\n",
    "        - Just a collection of data structerd in a certain way\n",
    "- Remember: items have to be on the same device in order to work togeter\n",
    "    - i.e. data on cpu can only work with network on cpu\n",
    "- Whenever possible, write device agnostic test (not an advice, something I think makes sense)\n",
    "\n",
    "#### Speed Difference Between CPU and CUDA\n",
    "<div>\n",
    "<img src=\"cuda_speed.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones(1,1,28,28)\n",
    "t.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = my_model.Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t\t torch.Size([6])\n",
      "conv2.weight \t\t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t\t torch.Size([12])\n",
      "fc1.weight \t\t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t\t torch.Size([120])\n",
      "fc2.weight \t\t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t\t torch.Size([60])\n",
      "out.weight \t\t\t torch.Size([10, 60])\n",
      "out.bias \t\t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu  conv1.weight\n",
      "cpu  conv1.bias\n",
      "cpu  conv2.weight\n",
      "cpu  conv2.bias\n",
      "cpu  fc1.weight\n",
      "cpu  fc1.bias\n",
      "cpu  fc2.weight\n",
      "cpu  fc2.bias\n",
      "cpu  out.weight\n",
      "cpu  out.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in network.named_parameters():\n",
    "    print(p.device, '', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- https://deeplizard.com/learn/video/Bs1mdHZiAS8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
