{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop for Hyperparameter Experimentation\n",
    "\n",
    "- A class to figure out the best hyperparameters\n",
    "- The calss will contain a static method get_runs() that will organize the hyperparameters into pairs of values, making it easier to conduct experiments\n",
    "\n",
    "<blockquote>Static methods, much like class methods, are methods that are bound to a class rather than its object. They do not require a class instance creation. So, they are not dependent on the state of the object.\n",
    "\n",
    "    ...\n",
    "When you need a utility function that doesn't access any properties of a class but makes sense that it belongs to the class, we use static functions.\n",
    "</blockquote>\n",
    "\n",
    "- The class returns a combination of hyperparameters using an ordered dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# print format\n",
    "torch.set_printoptions(linewidth=120) \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#! tensorboard --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(lr=0.01, batch_size=1000, device='cpu') 0.01 1000 cpu\n",
      "Run(lr=0.01, batch_size=1000, device='gpu') 0.01 1000 gpu\n",
      "Run(lr=0.01, batch_size=10000, device='cpu') 0.01 10000 cpu\n",
      "Run(lr=0.01, batch_size=10000, device='gpu') 0.01 10000 gpu\n",
      "Run(lr=0.001, batch_size=1000, device='cpu') 0.001 1000 cpu\n",
      "Run(lr=0.001, batch_size=1000, device='gpu') 0.001 1000 gpu\n",
      "Run(lr=0.001, batch_size=10000, device='cpu') 0.001 10000 cpu\n",
      "Run(lr=0.001, batch_size=10000, device='gpu') 0.001 10000 gpu\n"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [1000, 10000],\n",
    "    device = ['cpu', 'gpu']\n",
    ")\n",
    "\n",
    "runs = RunBuilder.get_runs(params)\n",
    "\n",
    "for run in runs:\n",
    "    print(run, run.lr, run.batch_size, run.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_model\n",
    "\n",
    "\n",
    "# Additional items required\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./Documents/data'\n",
    "     ,train=True\n",
    "    ,download=True # downloads it locally (checks existence beforehand)\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor() # butilt in tensor transformer\n",
    "    ])\n",
    ")\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [1000, 10000]\n",
    ")\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    #break\n",
    "    network = my_model.Network()\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    # Modify SummaryWriter with comment\n",
    "    comment = f' -{run}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    num_epochs = 5\n",
    "    # loop over all epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # variables to track\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        # loop over all batches in the train loader\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad() # zero grad because pytorch accumulates gradient\n",
    "            loss.backward() # calculate gradients\n",
    "            optimizer.step() # update weights\n",
    "\n",
    "            # update variables\n",
    "            # account for loss variation with respect to batch_size\n",
    "            total_loss += loss.item() * run.batch_size\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        # Add metrics to TensorBoard\n",
    "        # scalar -> tag, value, epoch\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct/len(train_set), epoch)\n",
    "        # histograms \n",
    "        tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "        tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "        tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "\n",
    "        # print information for selected epochs\n",
    "        if (epoch+1) % 2 == 0:\n",
    "            print(\"Epoch: \", epoch+1, \"\\n\\tAccuracy (%):\", total_correct/len(train_set),\n",
    "              \"\\n\\tLoss \", total_loss)\n",
    "\n",
    "\n",
    "    print(\"\\nNumber of steps taken towards the loss minimum:\", len(train_set)/run.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- https://www.programiz.com/python-programming/methods/built-in/staticmethod\n",
    "- https://deeplizard.com/learn/video/NSKghk0pcco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
