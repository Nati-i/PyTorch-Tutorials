{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "- Analysing your data and network\n",
    "- Live updates to accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transorms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "epoch 1 / 4, step 100 / 600, loss = 0.4947\n",
      "epoch 1 / 4, step 200 / 600, loss = 0.2512\n",
      "epoch 1 / 4, step 300 / 600, loss = 0.3413\n",
      "epoch 1 / 4, step 400 / 600, loss = 0.2466\n",
      "epoch 1 / 4, step 500 / 600, loss = 0.3156\n",
      "epoch 1 / 4, step 600 / 600, loss = 0.1684\n",
      "epoch 2 / 4, step 100 / 600, loss = 0.2453\n",
      "epoch 2 / 4, step 200 / 600, loss = 0.2227\n",
      "epoch 2 / 4, step 300 / 600, loss = 0.1021\n",
      "epoch 2 / 4, step 400 / 600, loss = 0.0760\n",
      "epoch 2 / 4, step 500 / 600, loss = 0.1291\n",
      "epoch 2 / 4, step 600 / 600, loss = 0.2560\n",
      "epoch 3 / 4, step 100 / 600, loss = 0.0732\n",
      "epoch 3 / 4, step 200 / 600, loss = 0.1079\n",
      "epoch 3 / 4, step 300 / 600, loss = 0.1764\n",
      "epoch 3 / 4, step 400 / 600, loss = 0.1672\n",
      "epoch 3 / 4, step 500 / 600, loss = 0.0738\n",
      "epoch 3 / 4, step 600 / 600, loss = 0.1932\n",
      "epoch 4 / 4, step 100 / 600, loss = 0.1009\n",
      "epoch 4 / 4, step 200 / 600, loss = 0.0750\n",
      "epoch 4 / 4, step 300 / 600, loss = 0.1466\n",
      "epoch 4 / 4, step 400 / 600, loss = 0.0610\n",
      "epoch 4 / 4, step 500 / 600, loss = 0.0457\n",
      "epoch 4 / 4, step 600 / 600, loss = 0.1498\n",
      "accuracy = 96.74\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 100\n",
    "# 10 different classes\n",
    "num_classes = 10 \n",
    "\n",
    "# training epochs\n",
    "num_epochs = 4\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transorms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                          transform=transorms.ToTensor())\n",
    "\n",
    "# dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                          shuffle=False) \n",
    "# shuffle false b/c doesn't matter for eval\n",
    "\n",
    "examples = iter(train_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "\n",
    "writer.close() # flush\n",
    "\n",
    "#sys.exit() # exit system before training occurs\n",
    "\n",
    "# setting up a fully connected NN with one hidden layer\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) # first layer\n",
    "        self.relu = nn.ReLU() # activation layer\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes) # second layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out) # no soft max here\n",
    "        return out\n",
    "\n",
    "# model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # this will apply the soft max, which is why it was not needed earlier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\n",
    "writer.close()\n",
    "#|sys.exit()\n",
    "\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over batches\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # reshape images first from 100, 1, 28, 28 ->\n",
    "        # input size = 784 \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step() # update step, updating parameters\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "            \n",
    "# testing loop and evaluation\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    # loop over batches in test samples\n",
    "    for images, labels in test_loader:\n",
    "        # reshape\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index -> returned by torch.max\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0] # gives the number of samples in current batch\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        labels.append(predictions)\n",
    "        # call softmax explicitly for output\n",
    "        class_predictions = [F.softmax(output, dim=0) for output in outputs]\n",
    "        preds.append(class_predictions)\n",
    "    \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels = torch.cat(labels) # concatenate all elements in the list to 1d tensor\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    \n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = labels == i\n",
    "        preds_i = preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
