{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "- Analysing your data and network\n",
    "- Live updates to accuracy and loss\n",
    "- precesion recall (PR) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transorms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 4, step 100 / 600, loss = 0.3251\n",
      "epoch 1 / 4, step 200 / 600, loss = 0.3053\n",
      "epoch 1 / 4, step 300 / 600, loss = 0.2466\n",
      "epoch 1 / 4, step 400 / 600, loss = 0.3427\n",
      "epoch 1 / 4, step 500 / 600, loss = 0.3433\n",
      "epoch 1 / 4, step 600 / 600, loss = 0.2716\n",
      "epoch 2 / 4, step 100 / 600, loss = 0.2506\n",
      "epoch 2 / 4, step 200 / 600, loss = 0.2674\n",
      "epoch 2 / 4, step 300 / 600, loss = 0.4236\n",
      "epoch 2 / 4, step 400 / 600, loss = 0.1645\n",
      "epoch 2 / 4, step 500 / 600, loss = 0.2341\n",
      "epoch 2 / 4, step 600 / 600, loss = 0.1120\n",
      "epoch 3 / 4, step 100 / 600, loss = 0.2127\n",
      "epoch 3 / 4, step 200 / 600, loss = 0.1155\n",
      "epoch 3 / 4, step 300 / 600, loss = 0.0963\n",
      "epoch 3 / 4, step 400 / 600, loss = 0.1601\n",
      "epoch 3 / 4, step 500 / 600, loss = 0.1660\n",
      "epoch 3 / 4, step 600 / 600, loss = 0.1940\n",
      "epoch 4 / 4, step 100 / 600, loss = 0.1789\n",
      "epoch 4 / 4, step 200 / 600, loss = 0.1085\n",
      "epoch 4 / 4, step 300 / 600, loss = 0.1615\n",
      "epoch 4 / 4, step 400 / 600, loss = 0.0392\n",
      "epoch 4 / 4, step 500 / 600, loss = 0.0887\n",
      "epoch 4 / 4, step 600 / 600, loss = 0.1333\n",
      "accuracy = 96.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 100\n",
    "# 10 different classes\n",
    "num_classes = 10 \n",
    "\n",
    "# training epochs\n",
    "num_epochs = 4\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transorms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                          transform=transorms.ToTensor())\n",
    "\n",
    "# dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                          shuffle=False) \n",
    "# shuffle false b/c doesn't matter for eval\n",
    "\n",
    "examples = iter(train_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "#print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "\n",
    "writer.close() # flush\n",
    "\n",
    "#sys.exit() # exit system before training occurs\n",
    "\n",
    "# setting up a fully connected NN with one hidden layer\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) # first layer\n",
    "        self.relu = nn.ReLU() # activation layer\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes) # second layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out) # no soft max here\n",
    "        return out\n",
    "\n",
    "# model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # this will apply the soft max, which is why it was not needed earlier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\n",
    "writer.close()\n",
    "#|sys.exit()\n",
    "\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over batches\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # reshape images first from 100, 1, 28, 28 ->\n",
    "        # input size = 784 \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step() # update step, updating parameters\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "            \n",
    "# testing loop and evaluation\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    # loop over batches in test samples\n",
    "    for images, labels1 in test_loader:\n",
    "        # reshape\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index -> returned by torch.max\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels1.shape[0] # gives the number of samples in current batch\n",
    "        n_correct += (predictions == labels1).sum().item()\n",
    "        \n",
    "        labels.append(predictions)\n",
    "        # call softmax explicitly for output\n",
    "        class_predictions = [F.softmax(output, dim=0) for output in outputs]\n",
    "        preds.append(class_predictions)\n",
    "    \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels = torch.cat(labels) # concatenate all elements in the list to 1d tensor\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    \n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = labels == i\n",
    "        preds_i = preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
