{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Normalization \n",
    "\n",
    "- How is a dataset normalized?\n",
    "    - Taking data points and transforming them into encoded formats\n",
    "    - Feature scaling\n",
    "    - Transforming to similar scales\n",
    "- How does dataset normalization affect the training process?\n",
    "    - If you have features of a different scale, such as age and weight, it would be useful to normalize the two such that they are on similar scales\n",
    "    - This is done by some sort of encoding transformations\n",
    "    \n",
    "## Standardization\n",
    "\n",
    "- A normalization process \n",
    "<blockquote>Data standardization is a specific type of normalization technique. It is sometimes referred to as z-score normalization. The z-score, a.k.a. standard score, is the transformed value for each data point.</blockquote>\n",
    "    Formula: $z = \\frac{x - mean}{std}$\n",
    "    In other words words: \n",
    "- Sometimes we have to calculate mean and standard deviation beforehand before we can standardize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./Documents/data'\n",
    "     ,train=True\n",
    "    ,download=True # downloads it locally (checks existence beforehand)\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor() # butilt in tensor transformer\n",
    "        # TODO: Normalize\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2859), tensor(0.3530), 4.861122131347656)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method one\n",
    "run_start_time = time.time()\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std(), (time.time() - run_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7ff60ae48990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean(),color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Might not Fit in Memory to be Loaded at Once\n",
    "\n",
    "- In this case, we need to caculate the mean and std using batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2859), tensor(0.3514), 8.463542938232422)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method Two\n",
    "run_start_time = time.time()\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
    "\n",
    "num_of_pixels = len(train_set) * 28 * 28\n",
    "\n",
    "total_sum = 0\n",
    "for batch in loader:\n",
    "    total_sum += batch[0].sum()\n",
    "\n",
    "mean = total_sum / num_of_pixels\n",
    "\n",
    "sum_of_squared_error = 0\n",
    "\n",
    "for batch in loader:\n",
    "    sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()\n",
    "    \n",
    "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
    "\n",
    "mean, std, (time.time() - run_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the **mean** and **std** values\n",
    "\n",
    "- Transform the data using the standardization method mentioned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root='./Documents/data'\n",
    "     ,train=True\n",
    "    ,download=True # downloads it locally (checks existence beforehand)\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor(), # butilt in tensor transformer\n",
    "        # TODO: Normalize\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the new mean and standard deviation\n",
    "\n",
    "- The mean should be (very) close to zero and the std to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2859), tensor(0.3530), 4.703320026397705)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method one\n",
    "run_start_time = time.time()\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std(), (time.time() - run_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7ff60dbaef10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean(),color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with the normalized dataset\n",
    "\n",
    "- We will be using the RunManager and the RunBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000],\n",
    "    num_workers = [1],\n",
    "    device = ['cpu'],\n",
    "    trainset = ['not_normal', 'normal']\n",
    ")\n",
    "\n",
    "trainsets = {\n",
    "    'not_normal': train_set,\n",
    "    'normal': train_set_normal\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        \n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        \n",
    "        return runs\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # we will need to extract a class out of these epoch values\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        \n",
    "    def begin_run(self, run, network, loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        \n",
    "        for k,v in self.run_params._asdict().items():\n",
    "            results[k] = v\n",
    "        \n",
    "        self.run_data.append(results)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "        \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        # underscore indicates that this method should not really \n",
    "        # be used outside this class\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self,fileName):\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient='columns',\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "        \n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SummaryWriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d793f10e84fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d32ae56f02c3>\u001b[0m in \u001b[0;36mbegin_run\u001b[0;34m(self, run, network, loader)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'-{run}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SummaryWriter' is not defined"
     ]
    }
   ],
   "source": [
    "#from my_model import RunManager\n",
    "#import time\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    network = my_model.Network()\n",
    "    \n",
    "    loader = DataLoader(trainsets[run.trainset], \n",
    "                        batch_size=run.batch_size, \n",
    "                        num_workers=run.num_workers)\n",
    "    \n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "            \n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "- https://www.youtube.com/watch?v=lu7TCu7HeYc&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=36&ab_channel=deeplizard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
