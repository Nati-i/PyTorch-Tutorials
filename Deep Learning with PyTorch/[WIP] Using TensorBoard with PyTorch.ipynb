{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard with PyTorch\n",
    "\n",
    "- TensorBoard, as mentioned earlier, is a visualization toolkit we could use in order to further understand our model\n",
    "    - It essentially reads data from a file and displays it\n",
    "        - Track and visualize metrics (loss, accuracy)\n",
    "        - Network graph\n",
    "        - Histograms of weights and biases\n",
    "- In order to use TensorBoard, we need to write the data into a file that TensorBoard can read\n",
    "    - PyTorch has a utility class which we can use for this called SummaryWriter \n",
    "- Run the following\n",
    "    - **tensorboard --logdir=runs**\n",
    "    - The above command will write a runs file containing data written to it using the SummaryWriter() class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# print format\n",
    "torch.set_printoptions(linewidth=120) \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#! tensorboard --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the forward method\n",
    "class Network(nn.Module): # extending nn.Module base class\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__() # initializing base class\n",
    "        # prebuilt layers\n",
    "        # 1 input channel, convolved by 6 different filters\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        # fully connected, or dense layers \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden layer reshape\n",
    "        # 4*4 -> height * width -> reduction due to conv operations\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer (10 classes)\n",
    "        # using the softmax fucntion which returns a positive probability that sum to 1\n",
    "        # but we won't use it here because it will be there in the loss function\n",
    "        # which will implicitly execute the softmax function \n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t, dim=1) -> done in the loss part implicitly\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./Documents/data'\n",
    "     ,train=True\n",
    "    ,download=True # downloads it locally (checks existence beforehand)\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor() # butilt in tensor transformer\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 5\n",
    "# loop over all epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # variables to track\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # loop over all batches in the train loader\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad() # zero grad because pytorch accumulates gradient\n",
    "        loss.backward() # calculate gradients\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "        # update variables\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    # print information\n",
    "    print(\"Epoch: \", epoch+1, \"\\n\\tAccuracy (%):\", total_correct/len(train_set),\n",
    "          \"\\n\\tLoss \", total_loss)\n",
    "\n",
    "\n",
    "print(\"\\nNumber of steps taken towards the loss minimum:\", len(train_set)/batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
