{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All about Tensors\n",
    "## Explaining Tensors Using a CNN Example\n",
    "\n",
    "- [?, color, height, width]\n",
    "- [3, 1, 28, 28] -> 3 images, each with one color scheme (greyscale), each with a dim of 28*28\n",
    "- The tensors change shape as they propagate through the networks so it is important to reshape them correctly \n",
    "    - Eg. color channels -> [filter] -> feature maps\n",
    "- Data must be passed through pre-processing routines to transform it to efficient tensor formats\n",
    "- PyTorch Tensors have some specific attributes\n",
    "    - dtype: data type of tensor float32, etc.\n",
    "    - devcie: device on tensor\n",
    "    - layout: tells about how tensors are laid out on memory\n",
    "- Tensor computations must be of the same data type (i.e int + int = okay), and also must be on the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "t = torch.Tensor()\n",
    "print(t.dtype)\n",
    "print(t.device)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the best options of creating PyTorch Tensors?\n",
    "\n",
    "- PyTorch has several ways which we can use to create tensors\n",
    "- All functions (except for the constructor method torch.Tensor()) allow us to set a dtype for our data\n",
    "- Some functions allow you to modify arrays without influencing tensors and viceversa\n",
    "    - zero memory-copy -> very efficient\n",
    "        - torch.as_tensor() -> go to function of choice for this category\n",
    "        - torch.from_numpy() -> only accepts numpy arrays\n",
    "    - Simply copying data\n",
    "        - torch.tensor() -> go to function of choice\n",
    "        - torch.Tensory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "data = np.array([1,2,3])\n",
    "# class constructor, uses global default dtype -> float32\n",
    "t1 = torch.Tensor(data)\n",
    "# factory function, OOP\n",
    "t2 = torch.tensor(data)\n",
    "# factory function\n",
    "t3 = torch.as_tensor(data)\n",
    "# factory function\n",
    "t4 = torch.from_numpy(data)\n",
    "print(t1.dtype, t2.dtype, t3.dtype, t4.dtype, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "- Reshaping Operations\n",
    "    - Mold and modify tensors into the shape you desire\n",
    "    - You can reshape a tensor as many ways as there are factors of the number of elements\n",
    "        - i.e. 12 elements -> (12 = 12*1; 6*2; 4*3) 6 reshapes (order matters too)\n",
    "    - Another way of reshaping is to squeeze and then unsqueeze to the desired tensor\n",
    "- Reduction Operations\n",
    "- Access Operations\n",
    "\n",
    "- Tensors need to be flattened before they are passed to a fully connected layer in a CNN\n",
    "    - My chromatograms are already flat, perhaps the baseline can be viewd as another channel\n",
    "    \n",
    "- In a CNN batch, you want to flatten each image in the batch because you need a prediction per each image\n",
    "    - <code> t.flatten(start_dim=1) <code>  \n",
    "        - <code> t.flatten(start_dim=1).shape <code> \n",
    "        eg. [3, 16] 3 images with 16 elements each\n",
    "    - <code> t.reshape(t.shape[0],-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "2\n",
      "tensor(12)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([\n",
    "    [1, 1, 1, 1],\n",
    "    [2, 2, 2, 2],\n",
    "    [3, 3, 3, 3]\n",
    "], dtype=torch.float32)\n",
    "print(\n",
    "    t.size(),\n",
    "    t.shape,\n",
    "    len(t.shape), # rank of tensor\n",
    "    torch.tensor(t.shape).prod(), # number of elements\n",
    "    t.numel(), # number of elements\n",
    "sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 2., 2.],\n",
      "        [2., 2., 3.],\n",
      "        [3., 3., 3.]])\n",
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n",
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# reshapes\n",
    "print(\n",
    "     t,\n",
    "     t.reshape(1,12),\n",
    "     #t.reshape(2,6), \n",
    "     #t.reshape(3,4),\n",
    "     t.reshape(4,3),\n",
    "     #t.reshape(6,2),\n",
    "     #t.reshape(12,1),\n",
    "sep='\\n')\n",
    "\n",
    "# flattening tensors\n",
    "# useful for fully connected NN after convolutional layers\n",
    "# the way it works is implemented as follows:\n",
    "def flatten(t):\n",
    "    t = t.reshape(1, -1)\n",
    "    t = t.squeeze()\n",
    "    return t\n",
    "print(t.flatten()) # 1d array containing all scalars\n",
    "#print(flatten(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1],\n",
      "         [1, 1, 1],\n",
      "         [1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2],\n",
      "         [2, 2, 2],\n",
      "         [2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3],\n",
      "         [3, 3, 3],\n",
      "         [3, 3, 3]]])\n",
      "torch.Size([3, 3, 3]) -> batch = 3\n",
      "\n",
      "Reshaped tensor \n",
      " tensor([[[[1, 1, 1],\n",
      "          [1, 1, 1],\n",
      "          [1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[2, 2, 2],\n",
      "          [2, 2, 2],\n",
      "          [2, 2, 2]]],\n",
      "\n",
      "\n",
      "        [[[3, 3, 3],\n",
      "          [3, 3, 3],\n",
      "          [3, 3, 3]]]])\n"
     ]
    }
   ],
   "source": [
    "# batch and tensors\n",
    "t1 = torch.tensor([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1], \n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2], \n",
    "    [2, 2, 2]\n",
    "])\n",
    "\n",
    "t3 = torch.tensor([\n",
    "    [3, 3, 3],\n",
    "    [3, 3, 3], \n",
    "    [3, 3, 3]\n",
    "])\n",
    "\n",
    "t = torch.stack((t1,t2,t3))\n",
    "print(t)\n",
    "print(t.shape, '-> batch = 3')\n",
    "\n",
    "print()\n",
    "print('Reshaped tensor \\n', t.reshape(3, 1, 3, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise Operations\n",
    "\n",
    "- Operates on tensor elements that correspond on index location \n",
    "- The tensors must have the same shape and number of elements\n",
    "    - Otherwise the operation will make use of broadcasting\n",
    "    - It is important to understand broadcasting, it will help you avoid writing unnecessary loops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor(1)\n",
      "tensor([9, 8])\n",
      "tensor(1)\n",
      "\n",
      "tensor([[10, 10],\n",
      "        [10, 10]])\n",
      "tensor([[8, 7],\n",
      "        [6, 5]])\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3,4]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [9,8],\n",
    "    [7,6]\n",
    "])\n",
    "\n",
    "print(t1[0], t1[0][0], sep='\\n')\n",
    "print(t2[0], t1[0][0], sep='\\n')\n",
    "print()\n",
    "print(t1+t2)\n",
    "print(t2-1)\n",
    "\n",
    "print(\n",
    "    t1 + torch.tensor(\n",
    "    np.broadcast_to(2, t1.shape),\n",
    "    dtype=torch.float32)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Reduction Operations\n",
    "\n",
    "- An operation that reduces the number of elements contained in a tensor\n",
    "    - sum, prod, mean, std etc.\n",
    "    - It is also possible to do these operations on a certain dimension \n",
    "    - Argmax -> max output value of a function (the index location)\n",
    "        - We use the argmax function on the output of a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.],\n",
      "        [2., 0., 2.],\n",
      "        [0., 3., 0.]])\n",
      "tensor(8.)\n",
      "9\n",
      "1\n",
      "tensor([2., 4., 2.])\n",
      "tensor([1., 4., 3.])\n",
      "\n",
      "Max value:  tensor(3.)  \n",
      "Location:  tensor(7)\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 3., 2.]),\n",
      "indices=tensor([1, 2, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([1, 0, 1]))\n",
      "\n",
      "tensor(0.8889)\n",
      "[0.6666667 1.3333334 0.6666667]\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([\n",
    "    [0,1,0],\n",
    "    [2,0,2],\n",
    "    [0,3,0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(t, t.sum(), t.numel(), t.sum().numel(), sep='\\n')\n",
    "print(t.sum(dim=0)) # column sum\n",
    "print(t.sum(dim=1)) # row sum\n",
    "print('\\nMax value: ', t.max(),' \\nLocation: ', t.argmax()) # index 7\n",
    "print()\n",
    "print(t.max(dim=0))\n",
    "print(t.max(dim=1))\n",
    "print()\n",
    "print(t.mean())\n",
    "print(t.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
