{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch\n",
    "- A deep learning framework that makes it easier to develop deep learning models\n",
    "- Torch based framework in python\n",
    "- Created and maintained by fb because the creator was working at fb when he created it\n",
    "- Tensors used in PyTorch are similar to numpy tensors i.e. fast low level computations\n",
    "- Allows us to use python debuggers \n",
    "- Use dybamic computational graphs to compute derivatives (in contrast to TF)\n",
    "\n",
    "### Packages in PyTorch\n",
    "\n",
    "- The packages in PyTorch allows us to create deep learning models in a simle way\n",
    "\n",
    "<div>\n",
    "<img src=\"packages.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "<blockquote>Software engineers can only write so much software, but machines can write much more.</blockquote>\n",
    "\n",
    "\n",
    "### Why do I want to use it for MT?\n",
    "- This seems to be the tool that is best suited for research purposes due to its dynamic computational graph. \n",
    "- I have never used PyTorch before so this will be a great opportunity to learn it.\n",
    "\n",
    "\n",
    "### Why are GPUs used in Deep Learning?\n",
    "- GPUs are good at handeling at specialised computations that can utilize parallel computing \n",
    "    - Graphics computations (vector calculations)\n",
    "- Neural networks are embarrassingly parallel \n",
    "    - Embarrassingly parallel: easy to parallelize\n",
    "    - Computations tend to be independent on eachother (think of convolutions)\n",
    "- Cuda is a software platform (API) that pairs with Nvidia GPU hardware\n",
    "- At bottle neck points of python, PyTorch drops into C, C++ and CUDA to speed up processing \n",
    "- PyTorch supports multiple GPUs\n",
    "- Why not run all computations on the GPU?\n",
    "    - Because GPU is fast only for specialized tasks\n",
    "    - Plus moving data from CPU -> GPU is costly\n",
    "\n",
    "<div>\n",
    "<img src=\"cuda.png\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "- Tensors are the primary data structures used in neural networks\n",
    "- A tensor is a mathematical generalization of groups of numbers such as lists, arrays, matricies etc. \n",
    "    - Number -> Scalar\n",
    "    - Array -> Vector\n",
    "    - 2D Array -> 2D Matrix\n",
    "    - nD Array -> nD Tensor\n",
    "- The following are tensor attributes\n",
    "    - Rank: the number of dimensions. 2d-tensor(2D matrix) -> rank 2 i.e. 2 axes\n",
    "        - How many indices are needed to access an element\n",
    "    - Axes: a specific dimension of a tensor\n",
    "    - Shape: a shape of a tensor is determined by the length of each axis\n",
    "        - Number of indicies available in each axis\n",
    "        - i.e. number of columns by number of rows\n",
    "        - reshaping is an important operation in NN programming # t.reshape(1,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contineu here\n",
    "https://www.youtube.com/watch?v=AiyK0idr4uM&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=6&ab_channel=deeplizard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "- https://www.youtube.com/watch?v=DBVLcgq2Eg0\n",
    "- https://www.youtube.com/watch?v=6stDhEA0wFQ\n",
    "- https://www.youtube.com/watch?v=xx310zM3tLs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
