{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard with PyTorch\n",
    "\n",
    "- TensorBoard, as mentioned earlier, is a visualization toolkit we could use in order to further understand our model\n",
    "    - It essentially reads data from a file and displays it\n",
    "        - Track and visualize metrics (loss, accuracy)\n",
    "        - Network graph\n",
    "        - Histograms of weights and biases\n",
    "- In order to use TensorBoard, we need to write the data into a file that TensorBoard can read\n",
    "    - PyTorch has a utility class which we can use for this called SummaryWriter \n",
    "- Run the following\n",
    "    - **tensorboard --logdir=runs**\n",
    "    - The above command will write a runs file containing data written to it using the SummaryWriter() class\n",
    "- One of the key things we could do with TensorBoard is to compare multiple runs\n",
    "    - This will allow us to compare runs side by side\n",
    "    - We can use to experiment and find out which parameters work best \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# print format\n",
    "torch.set_printoptions(linewidth=120) \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#! tensorboard --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the forward method\n",
    "class Network(nn.Module): # extending nn.Module base class\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__() # initializing base class\n",
    "        # prebuilt layers\n",
    "        # 1 input channel, convolved by 6 different filters\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        # fully connected, or dense layers \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden layer reshape\n",
    "        # 4*4 -> height * width -> reduction due to conv operations\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer (10 classes)\n",
    "        # using the softmax fucntion which returns a positive probability that sum to 1\n",
    "        # but we won't use it here because it will be there in the loss function\n",
    "        # which will implicitly execute the softmax function \n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t, dim=1) -> done in the loss part implicitly\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional items required\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./Documents/data'\n",
    "     ,train=True\n",
    "    ,download=True # downloads it locally (checks existence beforehand)\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor() # butilt in tensor transformer\n",
    "    ])\n",
    ")\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8564666666666667 \n",
      "\tLoss  232.38755886256695\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8715833333333334 \n",
      "\tLoss  205.62885503470898\n",
      "Epoch:  6 \n",
      "\tAccuracy (%): 0.8790166666666667 \n",
      "\tLoss  195.41866463422775\n",
      "Epoch:  8 \n",
      "\tAccuracy (%): 0.8842333333333333 \n",
      "\tLoss  187.49598574638367\n",
      "Epoch:  10 \n",
      "\tAccuracy (%): 0.8878666666666667 \n",
      "\tLoss  181.07690523564816\n",
      "\n",
      "Number of steps taken towards the loss minimum: 600.0\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "num_epochs = 10\n",
    "# loop over all epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # variables to track\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # loop over all batches in the train loader\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad() # zero grad because pytorch accumulates gradient\n",
    "        loss.backward() # calculate gradients\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "        # update variables\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    # Add metrics to TensorBoard\n",
    "    # scalar -> tag, value, epoch\n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct/len(train_set), epoch)\n",
    "    # histograms \n",
    "    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "        \n",
    "    # print information for selected epochs\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        print(\"Epoch: \", epoch+1, \"\\n\\tAccuracy (%):\", total_correct/len(train_set),\n",
    "          \"\\n\\tLoss \", total_loss)\n",
    "\n",
    "\n",
    "print(\"\\nNumber of steps taken towards the loss minimum:\", len(train_set)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapid Experimentation -- Hyperparameter Tuning\n",
    "\n",
    "- We will now modify the code above to show how TensorBoard can be used in order to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8102333333333334 \n",
      "\tLoss  31454.31646344252\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8166333333333333 \n",
      "\tLoss  31274.454530994408\n",
      "\n",
      "Number of steps taken towards the loss minimum: 6000.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.7854666666666666 \n",
      "\tLoss  35716.84761739336\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8164833333333333 \n",
      "\tLoss  31106.936360271648\n",
      "\n",
      "Number of steps taken towards the loss minimum: 6000.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8579333333333333 \n",
      "\tLoss  22807.459658384323\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8764166666666666 \n",
      "\tLoss  19858.607479929924\n",
      "\n",
      "Number of steps taken towards the loss minimum: 600.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8577333333333333 \n",
      "\tLoss  22955.647145211697\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.87405 \n",
      "\tLoss  20577.574764192104\n",
      "\n",
      "Number of steps taken towards the loss minimum: 600.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8013666666666667 \n",
      "\tLoss  31078.93568277359\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8598166666666667 \n",
      "\tLoss  22521.239042282104\n",
      "\n",
      "Number of steps taken towards the loss minimum: 60.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.7896333333333333 \n",
      "\tLoss  33177.84109711647\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.85775 \n",
      "\tLoss  23419.87919807434\n",
      "\n",
      "Number of steps taken towards the loss minimum: 60.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8590333333333333 \n",
      "\tLoss  23005.524496843573\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.88875 \n",
      "\tLoss  18131.219244403183\n",
      "\n",
      "Number of steps taken towards the loss minimum: 6000.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8634833333333334 \n",
      "\tLoss  22208.73031925643\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8896333333333334 \n",
      "\tLoss  17765.619577644393\n",
      "\n",
      "Number of steps taken towards the loss minimum: 6000.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8027 \n",
      "\tLoss  31781.72478079796\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8473166666666667 \n",
      "\tLoss  25067.759205400944\n",
      "\n",
      "Number of steps taken towards the loss minimum: 600.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.8209 \n",
      "\tLoss  28948.555648326874\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.8631166666666666 \n",
      "\tLoss  22464.25701826811\n",
      "\n",
      "Number of steps taken towards the loss minimum: 600.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.71915 \n",
      "\tLoss  44374.654829502106\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.7730833333333333 \n",
      "\tLoss  35103.96081209183\n",
      "\n",
      "Number of steps taken towards the loss minimum: 60.0\n",
      "Epoch:  2 \n",
      "\tAccuracy (%): 0.7147833333333333 \n",
      "\tLoss  45439.65280056\n",
      "Epoch:  4 \n",
      "\tAccuracy (%): 0.7738166666666667 \n",
      "\tLoss  35725.081861019135\n",
      "\n",
      "Number of steps taken towards the loss minimum: 60.0\n"
     ]
    }
   ],
   "source": [
    "# Import python tool to elegantly create hyperparameter combinations\n",
    "from itertools import product\n",
    "\n",
    "# Hyperparameters\n",
    "parameters = dict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [10, 100, 1000],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "\n",
    "param_values = list(parameters.values())\n",
    "\n",
    "# Loop over a product of param_values\n",
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    \n",
    "    network = Network()\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    # Modify SummaryWriter with comment\n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    num_epochs = 5\n",
    "    # loop over all epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # variables to track\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        # loop over all batches in the train loader\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad() # zero grad because pytorch accumulates gradient\n",
    "            loss.backward() # calculate gradients\n",
    "            optimizer.step() # update weights\n",
    "\n",
    "            # update variables\n",
    "            # account for loss variation with respect to batch_size\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        # Add metrics to TensorBoard\n",
    "        # scalar -> tag, value, epoch\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct/len(train_set), epoch)\n",
    "        # histograms \n",
    "        tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "        tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "        tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "\n",
    "        # print information for selected epochs\n",
    "        if (epoch+1) % 2 == 0:\n",
    "            print(\"Epoch: \", epoch+1, \"\\n\\tAccuracy (%):\", total_correct/len(train_set),\n",
    "              \"\\n\\tLoss \", total_loss)\n",
    "\n",
    "\n",
    "    print(\"\\nNumber of steps taken towards the loss minimum:\", len(train_set)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    " \n",
    "- https://deeplizard.com/learn/video/pSexXMdruFM\n",
    "- https://deeplizard.com/learn/video/ycxulUVoNbk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
